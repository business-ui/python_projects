{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/business-ui/python_projects/blob/master/NYC_Rolling_Sales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPxUVGDMvY1o"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BzMb1x0EvjSk",
    "outputId": "d5cb55e4-b881-42b9-8be9-c058483573b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow_core._api.v2.version' from 'c:\\\\users\\\\ryana\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\tensorflow_core\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # now import the tensorflow module\n",
    "print(tf.version)  # make sure the version is 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "fqqIZlZwwIwK",
    "outputId": "a276100a-5ce8-4d90-8498-9e79883d4bfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ryana\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZlCUZhz2uSM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCV73taVYpke"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "arA-fnlvvspV"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /content/nyc-rolling-sales.csv does not exist: '/content/nyc-rolling-sales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-85cd650f320e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/nyc-rolling-sales.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ryana\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryana\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryana\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryana\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryana\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/nyc-rolling-sales.csv does not exist: '/content/nyc-rolling-sales.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/content/nyc-rolling-sales.csv\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "5GBwCpgwwTGl",
    "outputId": "68298f92-0c5e-478f-810a-1d980943ec01"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "s5B3XEGkwUIv",
    "outputId": "3cfca370-262e-4991-dc55-a3d9ecbd9190"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WVcLaNuwXZE"
   },
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "del df['APARTMENT NUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZQuz4fbyI_h"
   },
   "outputs": [],
   "source": [
    "df['SALE DATE'] = pd.to_datetime(df['SALE DATE'], infer_datetime_format=True)\n",
    "df['TAX CLASS AT TIME OF SALE'] = df['TAX CLASS AT TIME OF SALE'].astype('category')\n",
    "df['TAX CLASS AT PRESENT'] = df['TAX CLASS AT PRESENT'].astype('category')\n",
    "df['LAND SQUARE FEET'] = pd.to_numeric(df['LAND SQUARE FEET'], errors='coerce')\n",
    "df['GROSS SQUARE FEET']= pd.to_numeric(df['GROSS SQUARE FEET'], errors='coerce')\n",
    "df['SALE PRICE'] = pd.to_numeric(df['SALE PRICE'], errors='coerce')\n",
    "df['BOROUGH'] = df['BOROUGH'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihc-gv7pwaF2"
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\" \",\"_\").str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "71ddzEiHTIdZ",
    "outputId": "5fda5b7f-7d92-4278-b71f-86752fd1db9b"
   },
   "outputs": [],
   "source": [
    "print(\"Number of duplicated rows:\",sum(df.duplicated(df.columns)))\n",
    "df = df.drop_duplicates(df.columns, keep='last')\n",
    "print(\"Duplicated rows deleted:\",sum(df.duplicated(df.columns))==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "LbnFC5vGxqfX",
    "outputId": "b88b5d5c-02b8-4122-b113-044a2588ab81"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZP-jHkqYw2tK"
   },
   "outputs": [],
   "source": [
    "miss=df.isnull().sum()/len(df)\n",
    "miss=miss[miss>0]\n",
    "miss.sort_values(inplace=True)\n",
    "miss.columns=[\"name\",\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "Cu_a8S1MxTiF",
    "outputId": "728d8978-835c-4ceb-afa7-02a4e82423a2"
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid',color_codes=True)\n",
    "sns.barplot(x=miss.index, y=miss.values)\n",
    "plt.xticks(rotation=90)\n",
    "sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9m9mOaQVx8yL"
   },
   "outputs": [],
   "source": [
    "# let's fill these missing values up with mean values.\n",
    "df['land_square_feet']=df['land_square_feet'].fillna(df['land_square_feet'].mean())\n",
    "df['gross_square_feet']=df['gross_square_feet'].fillna(df['gross_square_feet'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osuqghBp4nol"
   },
   "outputs": [],
   "source": [
    "# I want to add the weekday and month features to the dataset. January sales can differ from July sales.\n",
    "df['weekday'] = df['sale_date'].apply(lambda x: datetime.datetime.weekday(x))\n",
    "df['sale_day'] = pd.DatetimeIndex(df['sale_date']).day\n",
    "df['sale_month'] = pd.DatetimeIndex(df['sale_date']).month\n",
    "df['sale_year'] = pd.DatetimeIndex(df['sale_date']).year\n",
    "del df['sale_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 960
    },
    "colab_type": "code",
    "id": "gqYUtgEE24Nr",
    "outputId": "36e1c6b9-6fe8-41c0-9746-8269d24ab985"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(),annot=True,cmap=\"Spectral_r\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "_FSwiIhw3QAi",
    "outputId": "88fc8a81-474a-456d-b2cc-7cac17e49ca1"
   },
   "outputs": [],
   "source": [
    "# For a numeric representation of correlation with sale_price\n",
    "df.corr()['sale_price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "y1QkkK6s4d1Y",
    "outputId": "051a6b3f-378d-47a9-dd70-aa93003c5ae6"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Skjj992jBkSt"
   },
   "outputs": [],
   "source": [
    "# separating the tax_class_at_present column into number and letter columns for comparison with tax_class_at_time_of_sale (Boolean)\n",
    "df['tax_class_at_present'], df['tax_class_at_present_letter'] = df['tax_class_at_present'].str[0], df['tax_class_at_present'].str[1]\n",
    "df.loc[df['tax_class_at_present_letter'].isna(),'tax_class_at_present_letter'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CoXPI8-ICaG3"
   },
   "outputs": [],
   "source": [
    "# setting blank tax_class_at_present values to the tax_class_at_time_of_sale\n",
    "# same for building_class columns\n",
    "# this makes an assumption, but a reasonable one, that they are the same if the present value is blank\n",
    "df.loc[df['tax_class_at_present']==\" \", 'tax_class_at_present'] = df.loc[df['tax_class_at_present']==\" \", 'tax_class_at_time_of_sale']\n",
    "df.loc[df['building_class_at_present']==\" \", \"building_class_at_present\"] = df.loc[df['building_class_at_present']==\" \", \"building_class_at_time_of_sale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "y74hFGGAI30V",
    "outputId": "2d3dc4aa-025e-4335-950f-4a0bfdbd9307"
   },
   "outputs": [],
   "source": [
    "for col in df[['tax_class_at_present','tax_class_at_time_of_sale','building_class_at_present','building_class_at_time_of_sale']]:\n",
    "    print(col)\n",
    "    df[col] = df[col].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIlERzXWMD3x"
   },
   "outputs": [],
   "source": [
    "df.loc[(df['tax_class_at_present']!=df['tax_class_at_time_of_sale']) & (df['tax_class_at_present'].str.lower()==\"nan\"),\n",
    "       'tax_class_at_present'] = \\\n",
    "       df.loc[(df['tax_class_at_present']!=df['tax_class_at_time_of_sale']) & (df['tax_class_at_present'].str.lower()==\"nan\"),\n",
    "       'tax_class_at_time_of_sale']\n",
    "\n",
    "df.loc[(df['building_class_at_present']!=df['building_class_at_time_of_sale']) & (df['building_class_at_present'].str.lower()==\"nan\"),\n",
    "       'building_class_at_present'] = \\\n",
    "       df.loc[(df['building_class_at_present']!=df['building_class_at_time_of_sale']) & (df['building_class_at_present'].str.lower()==\"nan\"),\n",
    "       'building_class_at_time_of_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Wen_rUPS0Ys"
   },
   "outputs": [],
   "source": [
    "df['tax_class_stays_same'] = (df['tax_class_at_present']==df['tax_class_at_time_of_sale']).astype(\"int\")\n",
    "df['building_class_stays_same'] = (df['building_class_at_present']==df['building_class_at_time_of_sale']).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kF160XwPEJm7"
   },
   "outputs": [],
   "source": [
    "# have to get close with street addresses\n",
    "# an address searching algorithm would be best to normalize addresses and search for lat/long values\n",
    "df['address'] = df['address'].str.split(\",\",n=1,expand=True)[0].str.split(\" \",n=1,expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "JUFL_Hcy9MOd",
    "outputId": "9b4cb0b3-9597-4d8c-db1b-e6b9ccd9657c"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qc9NFF3jniq_",
    "outputId": "98c2ce93-0c26-491f-977b-fb29ed281130"
   },
   "outputs": [],
   "source": [
    "orig_data_length = len(df)\n",
    "df = df[(df['sale_price'] > 100000) & (df['sale_price'] < 5000000)]\n",
    "# df = df[df['gross_square_feet'] < 10000]\n",
    "# df = df[df['land_square_feet'] < 10000]\n",
    "# df = df[(df['total_units'] > 0) & (df['total_units'] != 2261)]\n",
    "print(\"Percentage of original data left:\",str(round((len(df)/orig_data_length)*100,1))+\"%\")\n",
    "print(\"New Dataset Shape:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mTbh5KCdc2bC",
    "outputId": "7dbc5611-97b8-4881-db2d-93c0567efbb1"
   },
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % df['sale_price'].skew())\n",
    "print(\"Kurtosis: %f\" % df['sale_price'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "8EAJIIR3c980",
    "outputId": "c20a5125-8599-422e-8f03-582472332826"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['sale_price'],fit=norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "nyKJZG1KdAnf",
    "outputId": "a59355cb-3acc-492e-d8e6-3ceae884b187"
   },
   "outputs": [],
   "source": [
    "stats.probplot(df['sale_price'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "Gw4ThIPkdC3f",
    "outputId": "c6ccf1d8-0fed-4046-afd2-6ccd873f823f"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['sale_price'].apply(np.log),fit=norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "9KmpTPaOb1Yv",
    "outputId": "5ed39bb1-224c-44ab-801d-a1b04764fb93"
   },
   "outputs": [],
   "source": [
    "stats.probplot(df['sale_price'].apply(np.log),plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uDYgIpD8mG2"
   },
   "source": [
    "The following algorithm is my **LOVELY** way of searching and comparing:\n",
    "*  \\# of outliers when log-transformed\n",
    "*  \\# of outliers without transformation\n",
    "\n",
    "The columns with less outliers when transformed are scaled and overwritten in the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "qZm6MO_5_Xup",
    "outputId": "82c548ed-e66e-4b05-b344-fc0b34a7b385"
   },
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=[np.number]).drop(['year_built','weekday','sale_month','sale_day','sale_year'], axis=1):\n",
    "    outliers = np.where(\n",
    "        np.abs(\n",
    "            stats.zscore(\n",
    "                df[col]\n",
    "            )\n",
    "        ) > 3 )[0]\n",
    "    \n",
    "    log_transformed_outliers = np.where(\n",
    "        np.abs(\n",
    "            stats.zscore(\n",
    "                df[col].apply(\n",
    "                    lambda x: np.log(x) if (x != 0) & (x != np.nan) else 1e-100\n",
    "                )\n",
    "            )\n",
    "        ) > 3 )[0]\n",
    "    \n",
    "    print(df[col].name)\n",
    "    print(\"outliers:\",len(outliers))\n",
    "    print(\"log transformed outliers:\",len(log_transformed_outliers))\n",
    "    print()\n",
    "    if len(log_transformed_outliers) < len(outliers):\n",
    "      df[col] = df[col].apply(lambda x: np.log(x) if (x != 0) & (x != np.nan) else 1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "qb_nVCkeFb3d",
    "outputId": "4e43e848-25ea-4e7f-edbc-bcaa15d9bd9b"
   },
   "outputs": [],
   "source": [
    "sales=df['sale_price']\n",
    "print(sales.skew())\n",
    "sns.distplot(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "_Xhp7B1VlRSl",
    "outputId": "15f7bb67-3381-452e-b426-8d8820251fba"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df.corr()['sale_price'].sort_values(ascending=False)).to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6u6_dXVG7YRA"
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['borough', \n",
    "                       'weekday', \n",
    "                       'sale_day',\n",
    "                       'sale_month', \n",
    "                       'sale_year', \n",
    "                       'tax_class_at_present_letter',\n",
    "                       'tax_class_stays_same',\n",
    "                       'building_class_stays_same',\n",
    "                       'tax_class_at_time_of_sale',\n",
    "                       'building_class_at_time_of_sale',\n",
    "                       'year_built',\n",
    "                       'neighborhood',\n",
    "                       'building_class_category',\n",
    "                       'tax_class_at_present',\n",
    "                       'block',\n",
    "                       'lot',\n",
    "                       'ease-ment',\n",
    "                       'building_class_at_present', \n",
    "                       'address',\n",
    "                       'zip_code']\n",
    "NUMERIC_COLUMNS = ['residential_units','commercial_units', 'total_units', 'land_square_feet','gross_square_feet']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  df[feature_name] = df[feature_name].astype('str')\n",
    "  vocabulary = df[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  df[feature_name] = df[feature_name].astype('float64')\n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHUUizOd3WVK"
   },
   "outputs": [],
   "source": [
    "dftrain, dfeval, y_train, y_eval = train_test_split(df,df.pop('sale_price'), test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myOeW-NXCH9-"
   },
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "  def input_function():  # inner function, this will be returned\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)  # randomize order of data\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "    return ds  # return a batch of the dataset\n",
    "  return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "eUQixf5tCxJ0",
    "outputId": "3835f75b-4726-4484-d9f2-1f4c2d1221fb"
   },
   "outputs": [],
   "source": [
    "estimator = tf.estimator.BoostedTreesRegressor(n_batches_per_layer=32,feature_columns=feature_columns,learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bpNlA4FWHbBs",
    "outputId": "9a40a61d-804d-4566-999b-d2a06a392e72"
   },
   "outputs": [],
   "source": [
    "estimator.train(train_input_fn)  # train\n",
    "result = estimator.evaluate(eval_input_fn)  # get model metrics/stats by evaluating testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRfTndDDX-Du"
   },
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def rmse(y_test,y_pred):\n",
    "      return np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "AImmHgKuF_bz",
    "outputId": "b8733c71-4b44-47e8-9e60-58f4c8dcb6a0"
   },
   "outputs": [],
   "source": [
    "pred_dicts = list(estimator.predict(eval_input_fn))\n",
    "\n",
    "preds = pd.Series([pred['predictions'][0] for pred in pred_dicts])\n",
    "\n",
    "actuals = y_eval.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "mYmtjHaSyWUQ",
    "outputId": "4132900a-1b78-4ae4-e49e-7c4fab65d72d"
   },
   "outputs": [],
   "source": [
    "print(actuals.head())\n",
    "print(preds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdYZnp1aLcq9"
   },
   "source": [
    "## Keep in mind that these are the log-transformed values of sale_price. \n",
    "## If you want to compute the errors with non-transformed values, use the following equation: \n",
    "## $$error = 10e^{actual} - 10e^{prediction}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Od_HtZbqGZA2",
    "outputId": "eca839a8-7bd8-41e0-9b91-0e5d10b23a36"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "colab_type": "code",
    "id": "fbl36pepPLbC",
    "outputId": "4b4b506e-1466-4c0c-a895-8f562ed22518"
   },
   "outputs": [],
   "source": [
    "error = actuals - preds\n",
    "print(error.describe())\n",
    "plt.hist(error, bins = 50,range=(-2,2))\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first thing we have to check is whether the residuals are biased or not. We know from elementary statistics that the mean value of the residuals is zero, so we can start checking with a Student’s t-test if it’s true or not for our holdout sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_val = stats.ttest_1samp(error)\n",
    "print(\"P-value of the residuals:\",p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see, the p-value is greater than 5%, so we cannot reject the null hypothesis and can say that the mean value of the holdout residuals is statistically similar to 0.\n",
    "## Then, we can test if the holdout residuals have the same average as the training ones. This is called Welch’s t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "4cD7x0kPmirz",
    "outputId": "ce7bc525-9f59-4ddf-ae5a-d6641551670d"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows= 1, ncols = 1)\n",
    "\n",
    "ax.scatter(x = actuals.apply(np.exp), y = preds.apply(np.exp))\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlim(11,16)\n",
    "ax.set_ylim(11,16)\n",
    "z = np.polyfit(actuals.apply(np.exp), preds.apply(np.exp), 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(actuals.apply(np.exp), p(actuals.apply(np.exp)),\"r--\")\n",
    "ax.set_title(\"Actual vs. Predicted values\")\n",
    "ax.set_xlabel(\"Actuals\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-ribccG-2OGy",
    "outputId": "36ce2084-cf3a-4af1-fd00-b80790d68b9f"
   },
   "outputs": [],
   "source": [
    "print('R^2 score: {}'.format(r2_score(actuals, preds)))\n",
    "\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse(actuals, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_val = stats.ttest_ind(actuals, preds, equal_var=False)\n",
    "print(\"The P-value of the two-sampled t-test:\",p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again, a p-value higher than 5% can make us tell that there aren’t enough reasons to assume that the mean values are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-test\n",
    "### After we have checked the mean value, there comes the variance. We obviously want that the holdout residuals show a behavior not so much different from the training residuals, so we can compare the variances of the two sets and check whether the holdout variance is higher than the training variance.\n",
    "### A good test to check if a variance is greater than another one is the F-test, but it only works with normally distributed residuals. If the distribution is not normal, the test might give wrong results.\n",
    "### So, if we really want to use this test, we must check the normality of the residuals using (for example) a Shapiro-Wilk test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_val = stats.shapiro(actuals)\n",
    "print(\"The P-value of the Shapiro test for the training data is:\",p_val)\n",
    "_, p_val = stats.shapiro(preds)\n",
    "print(\"The P-value of the Shapiro test for the test data is:\",p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.var(actuals) / np.var(preds)\n",
    "p_value = scipy.stats.f.cdf(F, actuals, preds)\n",
    "print(\"The P-value of the F test for difference of variances is:\",p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The p-value is 72%, which is greater than 5% and allows us to say that the two sets have the same variance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzTP8CCSMuJCD0IFKRVKHm",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NYC-Rolling-Sales.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
